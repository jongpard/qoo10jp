# ===== QOO10: í‚¤ ì¶”ì¶œ/ì •ê·œí™”/CSV/ë¹„êµ/ìŠ¬ë™ =====
import re, csv, json, time, os, datetime as dt
from pathlib import Path
from urllib.parse import urlparse, parse_qs
import requests

KST = dt.timezone(dt.timedelta(hours=9))
TODAY = dt.datetime.now(KST).date()
DATA_DIR = Path("data"); DATA_DIR.mkdir(parents=True, exist_ok=True)

# ---- ENV
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL", "")
GDRIVE_FOLDER_ID   = os.getenv("GDRIVE_FOLDER_ID", "")
GOOGLE_CLIENT_ID   = os.getenv("GOOGLE_CLIENT_ID", "")
GOOGLE_CLIENT_SECRET = os.getenv("GOOGLE_CLIENT_SECRET", "")
GOOGLE_REFRESH_TOKEN = os.getenv("GOOGLE_REFRESH_TOKEN", "")
SLACK_TRANSLATE_JA2KO = os.getenv("SLACK_TRANSLATE_JA2KO", "0")  # "1"ì´ë©´ ë²ˆì—­

# ---------- Slack ----------
def slack_post(text: str):
    if not SLACK_WEBHOOK_URL: 
        print("[Slack] ë¯¸ì„¤ì •")
        return
    try:
        requests.post(SLACK_WEBHOOK_URL, json={"text": text}, timeout=20).raise_for_status()
        print("[Slack] ì „ì†¡ OK")
    except Exception as e:
        print("[Slack] ì‹¤íŒ¨:", e)

# ---------- Google Drive (refresh_token) ----------
def google_oauth_token():
    url = "https://oauth2.googleapis.com/token"
    data = {
        "client_id": GOOGLE_CLIENT_ID,
        "client_secret": GOOGLE_CLIENT_SECRET,
        "refresh_token": GOOGLE_REFRESH_TOKEN,
        "grant_type": "refresh_token",
    }
    r = requests.post(url, data=data, timeout=30); r.raise_for_status()
    return r.json()["access_token"]

def drive_upload_file(path: Path) -> str:
    if not GDRIVE_FOLDER_ID: 
        print("[Drive] ë¯¸ì„¤ì •")
        return ""
    token = google_oauth_token()
    meta = {"name": path.name, "parents": [GDRIVE_FOLDER_ID]}
    files = {
        "metadata": ("metadata", json.dumps(meta), "application/json; charset=UTF-8"),
        "file": (path.name, open(path, "rb"), "text/csv"),
    }
    url = "https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart"
    r = requests.post(url, headers={"Authorization": f"Bearer {token}"}, files=files, timeout=60)
    r.raise_for_status()
    fid = r.json().get("id", "")
    print("[Drive] ì—…ë¡œë“œ:", fid)
    return fid

def drive_latest_prev(prefix: str) -> Path | None:
    """ë“œë¼ì´ë¸Œì—ì„œ prefixë¡œ ì‹œì‘í•˜ê³  ì˜¤ëŠ˜ ì´ì „ ë‚ ì§œê°€ í¬í•¨ëœ ìµœì‹  CSVë¥¼ ë‚´ë ¤ë°›ìŒ."""
    if not GDRIVE_FOLDER_ID: 
        return None
    token = google_oauth_token()
    q = f"'{GDRIVE_FOLDER_ID}' in parents and name contains '{prefix}' and trashed=false"
    url = "https://www.googleapis.com/drive/v3/files"
    params = {"q": q, "fields": "files(id,name,createdTime)", "orderBy":"createdTime desc", "pageSize":100}
    r = requests.get(url, headers={"Authorization": f"Bearer {token}"}, params=params, timeout=30)
    r.raise_for_status()
    for f in r.json().get("files", []):
        m = re.search(r"(\d{4}-\d{2}-\d{2})", f["name"])
        if not m: 
            continue
        d = dt.date.fromisoformat(m.group(1))
        if d < TODAY:
            # download
            out = DATA_DIR / "prev.csv"
            dl = requests.get(f"https://www.googleapis.com/drive/v3/files/{f['id']}?alt=media",
                              headers={"Authorization": f"Bearer {token}"}, timeout=60)
            dl.raise_for_status()
            out.write_bytes(dl.content)
            print("[Drive] ì „ì¼ CSV ë°›ìŒ:", out)
            return out
    return None

# ---------- Qoo10: ìƒí’ˆì½”ë“œ ì¶”ì¶œ/ì •ê·œí™” ----------
PID_RE_LIST = [
    re.compile(r"/(\d{8,12})(?:\?|$)"),           # .../1091763751?...
    re.compile(r"[?&](?:goodsNo|goodsno)=(\d+)"), # ?goodsNo=...
]

def extract_qoo10_pid(url: str) -> str:
    for rgx in PID_RE_LIST:
        m = rgx.search(url)
        if m: return m.group(1)
    return ""

NAME_CLEAN_RE = re.compile(r"(?:^å…¬å¼\b|\bNEW\b|\[[^\]]*\]|\([^)]+\)|\s{2,})")

def normalize_qoo10_text(s: str) -> str:
    # 'å…¬å¼' ì œê±°, ëŒ€ê´„í˜¸/ê´„í˜¸ ë¸”ëŸ­ ì œê±°, ë‹¤ì¤‘ ê³µë°± ì •ë¦¬
    s = NAME_CLEAN_RE.sub(" ", s).strip()
    return s

def make_key(name: str, url: str) -> str:
    pid = extract_qoo10_pid(url)
    return f"PID:{pid}" if pid else f"NM:{normalize_qoo10_text(name)}"

# ---------- CSV ----------
def save_qoo10_csv(items: list[dict], prefix: str) -> Path:
    """
    items: [{rank, brand, name, price, url, product_code(ì˜µì…˜)}]
    """
    path = DATA_DIR / f"{prefix}_{TODAY.isoformat()}.csv"
    with path.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["date","rank","brand","product_name","price","url","product_code"])
        for it in items:
            pid = it.get("product_code") or extract_qoo10_pid(it["url"])
            w.writerow([TODAY.isoformat(), it["rank"], it.get("brand",""),
                        it["name"], it.get("price",0), it["url"], pid])
    print("[CSV] ì €ì¥:", path)
    return path

def load_rows(path: Path) -> list[dict]:
    rows=[]
    if not path or not path.exists(): 
        return rows
    with path.open("r", encoding="utf-8") as f:
        r = csv.DictReader(f)
        for row in r:
            row["rank"]=int(row["rank"]); row["price"]=int(row.get("price","0") or "0")
            rows.append(row)
    return rows

# ---------- ë¹„êµ(ê¸‰ìƒìŠ¹/í•˜ë½/ë‰´ë­ì»¤/ì•„ì›ƒ) ----------
def analyze(today_rows, prev_rows, top_n_for_new=30, limit_rise=3, limit_fall=5, limit_new=3):
    def key_of(row):
        pid = row.get("product_code") or extract_qoo10_pid(row["url"])
        return f"PID:{pid}" if pid else f"NM:{normalize_qoo10_text(row['product_name'])}"

    t_map = {key_of(r): r for r in today_rows}
    p_map = {key_of(r): r for r in prev_rows}
    common = list(t_map.keys() & p_map.keys())

    rises=[]; falls=[]
    for k in common:
        t = t_map[k]["rank"]; p = p_map[k]["rank"]
        diff = p - t
        if diff>0:  rises.append((diff, t_map[k], p_map[k]))
        elif diff<0: falls.append((-diff, t_map[k], p_map[k]))

    rises.sort(key=lambda x:(-x[0], x[1]["rank"]))
    falls.sort(key=lambda x:(-x[0], x[1]["rank"]))

    # new / out
    new_rankers=[]
    for k,r in t_map.items():
        if r["rank"]<=top_n_for_new and k not in p_map:
            new_rankers.append(r)
        elif r["rank"]<=top_n_for_new and k in p_map and p_map[k]["rank"]>top_n_for_new:
            new_rankers.append(r)
    new_rankers.sort(key=lambda r:r["rank"])

    rank_outs=[]
    for k,r in p_map.items():
        if r["rank"]<=top_n_for_new and (k not in t_map or t_map[k]["rank"]>top_n_for_new):
            rank_outs.append(r)

    return rises[:limit_rise], new_rankers[:limit_new], falls[:limit_fall], len(new_rankers)+len(rank_outs)

# ---------- (ì„ íƒ) ì¼ë³¸ì–´â†’í•œêµ­ì–´ ë²ˆì—­ ----------
def maybe_translate(text: str) -> str:
    if SLACK_TRANSLATE_JA2KO != "1": 
        return text
    try:
        # ê°„ë‹¨í•œ ë¬´ë£Œ API íšŒí”¼ìš©: êµ¬ê¸€ ë²ˆì—­ ì›¹ì—”ì§„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ì´ ë§‰íˆëŠ” ê²½ìš°ê°€ ë§ì•„
        # ì—¬ê¸°ì„  ìŠ¬ë™ ë©”ì‹œì§€ ê¸¸ì´ ì¤„ì´ê¸°ì— ì§‘ì¤‘í•˜ê³  ë²ˆì—­ ì‹¤íŒ¨ëŠ” ì¡°ìš©íˆ ë¬´ì‹œ
        from googletrans import Translator  # requirementsì— googletrans==4.0.0-rc1
        tr = Translator()
        # ì˜ì–´/ìˆ«ìë§Œì¸ ì¤„ì€ ë²ˆì—­ ì•ˆ í•¨
        def needs_ja(s): return bool(re.search(r"[\u3040-\u30ff\u3400-\u9fff]", s))
        lines=[]
        for ln in text.splitlines():
            if needs_ja(ln):
                lines.append(tr.translate(ln, src="ja", dest="ko").text)
            else:
                lines.append(ln)
        return "\n".join(lines)
    except Exception:
        return text

# ---------- Slack ë©”ì‹œì§€ ----------
def build_slack_qoo10(today_rows, rises, new_rankers, falls, inout_cnt, title_date):
    top10 = [r for r in today_rows if r["rank"]<=10]
    def line(r):
        brand = normalize_qoo10_text(r.get("brand","")).replace("å…¬å¼","").strip()
        name  = normalize_qoo10_text(r["product_name"])
        head  = f"{brand} " if brand else ""
        price = f" â€” Â¥{r['price']:,}" if r.get("price") else ""
        return f"{r['rank']}. <{r['url']}|{head}{name}>{price}"

    msg=[]
    msg.append(f"*íí… ì¬íŒ¬ ë·°í‹° ë­í‚¹ â€” {title_date}*")
    msg.append("")
    msg.append("*TOP 10*")
    for r in top10:
        msg.append(line(r))

    # sections
    if rises:
        msg.append("\nğŸ”¥ *ê¸‰ìƒìŠ¹*")
        for diff,t,p in rises:
            msg.append(f"- {normalize_qoo10_text(t['product_name'])} {p['rank']}ìœ„ â†’ {t['rank']}ìœ„ (â†‘{diff})")
    else:
        msg.append("\nğŸ”¥ *ê¸‰ìƒìŠ¹*\n- í•´ë‹¹ ì—†ìŒ")

    if new_rankers:
        msg.append("\nğŸ†• *ë‰´ë­ì»¤*")
        for r in new_rankers:
            msg.append(f"- {normalize_qoo10_text(r['product_name'])} NEW â†’ {r['rank']}ìœ„")
    else:
        msg.append("\nğŸ†• *ë‰´ë­ì»¤*\n- í•´ë‹¹ ì—†ìŒ")

    if falls:
        msg.append("\nğŸ“‰ *ê¸‰í•˜ë½*")
        for diff,t,p in falls:
            msg.append(f"- {normalize_qoo10_text(t['product_name'])} {p['rank']}ìœ„ â†’ {t['rank']}ìœ„ (â†“{diff})")
    else:
        msg.append("\nğŸ“‰ *ê¸‰í•˜ë½*\n- í•´ë‹¹ ì—†ìŒ")

    msg.append("\nğŸ”— *ë­í¬ ì¸&ì•„ì›ƒ*")
    msg.append(f"{inout_cnt}ê°œì˜ ì œí’ˆì´ ì¸&ì•„ì›ƒ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return "\n".join(msg)

# ---------- ë©”ì¸ì—ì„œ ì´ë ‡ê²Œ ì‚¬ìš©í•˜ì„¸ìš” ----------
def qoo10_pipeline(items: list[dict]):
    """
    items ì˜ˆì‹œ ìŠ¤í‚¤ë§ˆ(í¬ë¡¤ëŸ¬ê°€ ì±„ì›Œì¤Œ):
      {'rank':1,'brand':'å…¬å¼ ãƒ‡ã‚¤ã‚¸ãƒ¼ã‚¯','name':'[8/15~19] å…¨å“999å††â€¦', 'price':999,
       'url':'https://www.qoo10.jp/item/.../1091763751?...'}
    """
    # 1) PID/ì •ê·œí™” í‚¤ ë³´ê°•
    for it in items:
        it["product_code"] = extract_qoo10_pid(it["url"])
        it["name"] = normalize_qoo10_text(it["name"])
        if "brand" in it:
            it["brand"] = normalize_qoo10_text(it["brand"]).replace("å…¬å¼","").strip()

    # 2) CSV ì €ì¥/ì—…ë¡œë“œ
    csv_path = save_qoo10_csv(
        [{"rank":it["rank"], "brand":it.get("brand",""), "name":it["name"],
          "price":it.get("price",0), "url":it["url"], "product_code":it.get("product_code","")}
         for it in items],
        prefix="íí…ì¬íŒ¬_ë·°í‹°_ë­í‚¹"
    )
    drive_upload_file(csv_path)

    # 3) ì „ì¼ CSV ë¡œë“œ
    prev_path = drive_latest_prev("íí…ì¬íŒ¬_ë·°í‹°_ë­í‚¹_")
    today_rows = load_rows(csv_path)
    prev_rows = load_rows(prev_path) if prev_path else []

    # 4) ë¹„êµ
    rises, new_rankers, falls, inout_cnt = analyze(
        today_rows, prev_rows,
        top_n_for_new=30, limit_rise=3, limit_fall=5, limit_new=3
    )

    # 5) ìŠ¬ë™
    msg = build_slack_qoo10(today_rows, rises, new_rankers, falls, inout_cnt, TODAY.isoformat())
    msg = maybe_translate(msg)  # JAâ†’KO(ì˜µì…˜)
    slack_post(msg)
# ===== END QOO10 BLOCK =====
