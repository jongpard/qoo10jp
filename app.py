# app.py
import os
import re
import csv
import sys
import json
import time
import math
import shutil
import random
import logging
import pathlib
import datetime as dt
from typing import List, Dict, Optional, Tuple

import requests
from bs4 import BeautifulSoup

# ë²ˆì—­(ì˜µì…˜) - googletrans (ë¬´ë£Œ). ì‹¤íŒ¨í•´ë„ ì „ì²´ ë¡œì§ì—ëŠ” ì˜í–¥ ì—†ë„ë¡ ë°©ì–´.
try:
    from googletrans import Translator  # pip install googletrans==4.0.0-rc1
except Exception:  # pragma: no cover
    Translator = None  # type: ignore

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…/ë‹¤ìš´
from googleapiclient.discovery import build  # pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib
from googleapiclient.http import MediaFileUpload
from google.oauth2.credentials import Credentials

# Playwright í´ë°±
from playwright.sync_api import sync_playwright

# ---------------------------- ì„¤ì • ----------------------------
QOO10_URL = "https://www.qoo10.jp/gmkt.inc/Mobile/Bestsellers/Default.aspx?group_code=2"
OUT_DIR = pathlib.Path("data")
OUT_DIR.mkdir(parents=True, exist_ok=True)

KST = dt.timezone(dt.timedelta(hours=9))
TODAY = dt.datetime.now(KST).date()
DATE_STR = TODAY.isoformat()

CSV_NAME = f"íí…ì¬íŒ¬_ë·°í‹°_ë­í‚¹_{DATE_STR}.csv"
CSV_PATH = OUT_DIR / CSV_NAME

# ìŠ¬ë™ ì¶œë ¥ ê°œìˆ˜ ì œí•œ
TOP_N = 10
RISING_LIMIT = 5
NEWCOMER_LIMIT = 5
FALLING_LIMIT = 5

# ë²ˆì—­ ì¤„ ë…¸ì¶œ(ê¸¸ì´ ì ˆì•½ì„ ìœ„í•´ ê¸°ë³¸ False)
SHOW_TRANSLATION = os.getenv("SLACK_TRANSLATE_JA2KO", "").strip() == "1"

# ë¡œê¹…
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s | %(message)s",
)
log = logging.getLogger("qoo10jp")

# --------------------- ìœ í‹¸ ---------------------
_jp_bracket = re.compile(r"[ã€\[].*?[ã€‘\]]|\(.*?\)|ï¼ˆ.*?ï¼‰")
_num_clean = re.compile(r"[^\d]+")

def parse_int(text: str) -> Optional[int]:
    if not text:
        return None
    m = _num_clean.sub("", str(text))
    if not m:
        return None
    try:
        return int(m)
    except Exception:
        return None

def parse_price(text: str) -> Optional[int]:
    """
    "Â¥1,110" -> 1110
    """
    if not text:
        return None
    return parse_int(text)

def extract_code_from_url(url: str) -> Optional[str]:
    # https://www.qoo10.jp/item/.../<code>?....
    m = re.search(r"/(\d+)(?:\?|$)", url)
    return m.group(1) if m else None

def clean_name(name: str) -> str:
    s = name or ""
    s = s.replace("å…¬å¼", "")
    s = _jp_bracket.sub("", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def now_kst_str():
    return dt.datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")

# --------------------- ë²ˆì—­(ì˜µì…˜) ---------------------
def ja_to_ko_batch(texts: List[str]) -> List[str]:
    if not SHOW_TRANSLATION:
        return ["" for _ in texts]
    if not texts:
        return []
    if Translator is None:
        return ["" for _ in texts]
    try:
        tr = Translator()
        out = []
        for t in texts:
            if not t:
                out.append("")
                continue
            try:
                r = tr.translate(t, src="ja", dest="ko")
                out.append(r.text)
            except Exception:
                out.append("")
        return out
    except Exception:
        return ["" for _ in texts]

# --------------------- HTTP ìˆ˜ì§‘ ---------------------
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/119.0.0.0 Safari/537.36",
    "Accept-Language": "ja-JP,ja;q=0.9,ko-KR;q=0.8,ko;q=0.7,en;q=0.6",
}

def fetch_http() -> str:
    log.info("HTTP ìˆ˜ì§‘ ì‹œë„: %s", QOO10_URL)
    r = requests.get(QOO10_URL, headers=HEADERS, timeout=20)
    r.raise_for_status()
    html = r.text
    if "Bestsellers" not in html and "Best Sellers" not in html:
        raise RuntimeError("HTTP ì‘ë‹µì´ ë¹„ì •ìƒìœ¼ë¡œ ë³´ì„(í‚¤ì›Œë“œ ë¯¸ê²€ì¶œ).")
    return html

# --------------------- Playwright í´ë°± ---------------------
def fetch_playwright() -> str:
    log.info("[Playwright] í´ë°± ì§„ì…")
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        ctx = browser.new_context(locale="ja-JP")
        page = ctx.new_page()
        page.goto(QOO10_URL, wait_until="domcontentloaded", timeout=30_000)
        # ëª¨ë°”ì¼ í˜ì´ì§€ëŠ” ë­í‚¹ ì„¹ì…˜ì´ ë°”ë¡œ ë…¸ì¶œë¨. ê°€ë²¼ìš´ ëŒ€ê¸° + ìŠ¤í¬ë¡¤ë¡œ ë” ë¡œë“œ.
        page.wait_for_timeout(1500)
        # 200ìœ„ê¹Œì§€ í‘œì‹œë˜ë„ë¡ ì¶©ë¶„íˆ ìŠ¤í¬ë¡¤
        for _ in range(10):
            page.mouse.wheel(0, 2000)
            page.wait_for_timeout(600)
        content = page.content()
        ctx.close()
        browser.close()
        return content

# --------------------- íŒŒì„œ ---------------------
def parse_qoo10(html: str) -> List[Dict]:
    """
    ë§¤ìš° ë‹¤ì–‘í•œ DOM ë³€í˜•ì„ ê³ ë ¤í•˜ì—¬ ìµœëŒ€í•œ ë³´ìˆ˜ì ìœ¼ë¡œ íŒŒì‹±.
    - ë­í‚¹ ìˆ«ì, ìƒí’ˆëª…, ê°€ê²©, ë§í¬
    """
    soup = BeautifulSoup(html, "html.parser")

    # ìƒí’ˆ ì¹´ë“œ í›„ë³´ë“¤
    candidates = []
    # ì¼ë°˜ì ìœ¼ë¡œ li ìš”ì†Œ ë‚´ a[href*="/item/"] ì¡´ì¬
    for a in soup.select('a[href*="/item/"]'):
        card = a.find_parent(["li", "div"])
        if card and card not in candidates:
            candidates.append(card)

    items: List[Dict] = []
    seen_urls = set()

    rank_guess = 0
    for c in candidates:
        a = c.select_one('a[href*="/item/"]')
        if not a:
            continue
        url = a.get("href") or ""
        if not url or url in seen_urls:
            continue
        seen_urls.add(url)

        # ì´ë¦„: a í…ìŠ¤íŠ¸ ë˜ëŠ” ì¹´ë“œ ë‚´ ëŒ€í‘œ í…ìŠ¤íŠ¸
        name = a.get_text(" ", strip=True)
        if not name:
            name = c.get_text(" ", strip=True)

        # ê°€ê²©: "Â¥1,110" í˜•íƒœ ì°¾ê¸°
        price_node = None
        # ê°€ê²© í›„ë³´ í…ìŠ¤íŠ¸
        for cand in c.find_all(text=True):
            t = str(cand).strip()
            if t.startswith("Â¥") and any(ch.isdigit() for ch in t):
                price_node = t
                break
        price = parse_price(price_node) if price_node else None

        # ì¹´ë“œ ë‚´ ë­í‚¹ ìˆ«ì ì¶”ì • (ì—†ìœ¼ë©´ ëˆ„ì  ì¹´ìš´í„°)
        rank = None
        # ìˆ«ìë§Œ ìˆëŠ” ì‘ì€ ë°°ì§€/ìŠ¤íŒ¬ íƒìƒ‰
        for s in c.select("em, i, b, strong, span"):
            t = (s.get_text() or "").strip()
            if t.isdigit():
                vi = int(t)
                if 1 <= vi <= 500:
                    rank = vi
                    break
        if rank is None:
            rank_guess += 1
            rank = rank_guess

        code = extract_code_from_url(url)

        items.append({
            "rank": rank,
            "name": name,
            "price": price,
            "url": url,
            "code": code,
        })

    # ë­í‚¹ìœ¼ë¡œ ì •ë ¬ + ì¤‘ë³µ ì œê±°
    items.sort(key=lambda x: x["rank"])
    uniq = []
    used_rank = set()
    for it in items:
        r = it["rank"]
        if r in used_rank:
            continue
        used_rank.add(r)
        uniq.append(it)

    # ìƒìœ„ 200ê¹Œì§€ë§Œ ì‚¬ìš©(ê¸¸ì´ ê³¼ë„ ë°©ì§€)
    return uniq[:200]

# --------------------- ì „/ë‹¹ì¼ ë¹„êµ ---------------------
def read_prev_from_drive() -> Optional[pathlib.Path]:
    """
    êµ¬ê¸€ë“œë¼ì´ë¸Œ í´ë”ì—ì„œ ì˜¤ëŠ˜ ì´ì „ ë‚ ì§œì˜ 'íí…ì¬íŒ¬_ë·°í‹°_ë­í‚¹_YYYY-MM-DD.csv' ì¤‘ ê°€ì¥ ìµœê·¼ ê²ƒì„ ë°›ì•„ì˜¨ë‹¤.
    ì‹¤íŒ¨í•˜ë©´ None.
    """
    folder_id = os.getenv("GDRIVE_FOLDER_ID", "").strip()
    if not folder_id:
        log.info("[Drive] í´ë” ID ì—†ìŒ â†’ ì „ì¼ ë¹„êµ ìƒëµ")
        return None

    try:
        creds = Credentials(
            None,
            refresh_token=os.getenv("GOOGLE_REFRESH_TOKEN"),
            token_uri="https://oauth2.googleapis.com/token",
            client_id=os.getenv("GOOGLE_CLIENT_ID"),
            client_secret=os.getenv("GOOGLE_CLIENT_SECRET"),
            scopes=["https://www.googleapis.com/auth/drive.readonly"],
        )
        svc = build("drive", "v3", credentials=creds)

        prefix = "íí…ì¬íŒ¬_ë·°í‹°_ë­í‚¹_"
        q = f"'{folder_id}' in parents and name contains '{prefix}' and mimeType='text/csv' and trashed=false"
        files = svc.files().list(q=q, orderBy="name desc", pageSize=50, fields="files(id,name)").execute().get("files", [])

        target = None
        for f in files:
            # ì˜¤ëŠ˜ íŒŒì¼ì€ íŒ¨ìŠ¤
            if DATE_STR in f["name"]:
                continue
            target = f
            break
        if not target:
            log.info("[Drive] ì „ì¼ CSV ì—†ìŒ")
            return None

        # ë‹¤ìš´ë¡œë“œ
        tmp = OUT_DIR / f"_prev_{target['name']}"
        req = svc.files().get_media(fileId=target["id"])
        fh = open(tmp, "wb")
        downloader = requests.Response()
        from googleapiclient.http import MediaIoBaseDownload
        import io
        stream = io.BytesIO()
        downloader = MediaIoBaseDownload(stream, req)
        done = False
        while not done:
            status, done = downloader.next_chunk()
        fh.write(stream.getvalue())
        fh.close()
        log.info("[Drive] ì „ì¼ CSV ë‹¤ìš´ë¡œë“œ: %s", tmp)
        return tmp
    except Exception as e:
        log.warning("[Drive] ì „ì¼ CSV ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: %s", e)
        return None

def load_csv(path: pathlib.Path) -> List[Dict]:
    rows: List[Dict] = []
    if not path or not path.exists():
        return rows
    with open(path, "r", encoding="utf-8", newline="") as f:
        rd = csv.DictReader(f)
        for r in rd:
            try:
                rows.append({
                    "date": r.get("date"),
                    "rank": int(r.get("rank", "0")),
                    "name": r.get("name", ""),
                    "price": int(r.get("price") or 0),
                    "url": r.get("url", ""),
                    "code": r.get("code", ""),
                })
            except Exception:
                continue
    return rows

def save_csv(path: pathlib.Path, items: List[Dict]):
    with open(path, "w", encoding="utf-8", newline="") as f:
        wr = csv.writer(f)
        wr.writerow(["date", "rank", "name", "price", "url", "code"])
        for it in items:
            wr.writerow([DATE_STR, it["rank"], it["name"], it.get("price") or "", it["url"], it.get("code") or ""])

def analyze(prev: List[Dict], curr: List[Dict]) -> Tuple[List[Tuple[Dict,int]], List[Dict], List[Tuple[Dict,int]], int]:
    """
    return: (rising, newcomers, falling, inout_count)
    - rising: [(item, +delta)]
    - newcomers: [item]
    - falling: [(item, -delta)]
    """
    prev_map = {}
    for r in prev:
        prev_map[r.get("code") or r["url"]] = r

    rising: List[Tuple[Dict,int]] = []
    newcomers: List[Dict] = []
    falling: List[Tuple[Dict,int]] = []
    inout = 0

    # í˜„í–‰ top30 ëŒ€ìƒ
    curr_top30 = [x for x in curr if x["rank"] <= 30]
    prev_top30_map = { (r.get("code") or r["url"]): r for r in prev if r["rank"] <= 30 }

    # newcomers / rising / falling
    for it in curr:
        key = it.get("code") or it["url"]
        pv = prev_map.get(key)
        if pv:
            delta = pv["rank"] - it["rank"]
            if delta > 0:
                rising.append((it, delta))
            elif delta < 0:
                falling.append((it, -delta))
        else:
            # ì´ì „ì— ì—†ì—ˆê³  í˜„ì¬ top30ì— ë“¤ë©´ ë‰´ë­ì»¤
            if it["rank"] <= 30:
                newcomers.append(it)

    # ë­í¬ ì•„ì›ƒ ì¹´ìš´íŠ¸(ì „ì¼ top30ì¸ë° ì˜¤ëŠ˜ >30 ë˜ëŠ” ë¯¸ë“±ì¥)
    for k, pv in prev_top30_map.items():
        cur = next((x for x in curr if (x.get("code") or x["url"]) == k), None)
        if (cur is None) or (cur["rank"] > 30):
            inout += 1

    # ì •ë ¬
    rising.sort(key=lambda x: (-x[1], x[0]["rank"], prev_map[(x[0].get("code") or x[0]["url"])]["rank"], clean_name(x[0]["name"])))
    newcomers.sort(key=lambda x: x["rank"])
    falling.sort(key=lambda x: (-x[1], x[0]["rank"], clean_name(x[0]["name"])))

    return rising, newcomers, falling, inout

# --------------------- Slack ë©”ì‹œì§€ ---------------------
def _fmt_price_yen(v: Optional[int]) -> str:
    return f"Â¥{v:,}" if isinstance(v, int) and v > 0 else "Â¥-"

def _line_linked(rank: int, name: str, price: Optional[int], url: str) -> str:
    txt = f"{rank}. {clean_name(name)} â€” {_fmt_price_yen(price)}"
    return f"<{url}|{txt}>"

def build_slack_message(
    date_str: str,
    top_items: List[Dict],
    rising: List[Tuple[Dict,int]],
    newcomers: List[Dict],
    falling: List[Tuple[Dict,int]],
    inout_count: int,
) -> str:
    lines: List[str] = []
    lines.append(f"*íí… ì¬íŒ¬ ë·°í‹° ë­í‚¹ â€” {date_str}*")
    lines.append("")

    # TOP 10
    lines.append("*TOP 10*")
    for it in top_items[:TOP_N]:
        lines.append(_line_linked(it["rank"], it["name"], it.get("price"), it["url"]))
        if SHOW_TRANSLATION and it.get("name_ko"):
            if it["name_ko"]:
                lines.append(it["name_ko"])

    # ê¸‰ìƒìŠ¹
    lines.append("")
    lines.append("ğŸ”¥ *ê¸‰ìƒìŠ¹*")
    if rising:
        for it, delta in rising[:RISING_LIMIT]:
            lines.append(f"- {clean_name(it['name'])} â†’ *{it['rank']}ìœ„* (â–²{delta})")
    else:
        lines.append("- í•´ë‹¹ ì—†ìŒ")

    # ë‰´ë­ì»¤
    lines.append("")
    lines.append("ğŸ†• *ë‰´ë­ì»¤*")
    if newcomers:
        for it in newcomers[:NEWCOMER_LIMIT]:
            lines.append(f"- {clean_name(it['name'])} NEW â†’ *{it['rank']}ìœ„*")
    else:
        lines.append("- í•´ë‹¹ ì—†ìŒ")

    # ê¸‰í•˜ë½
    lines.append("")
    lines.append("ğŸ“‰ *ê¸‰í•˜ë½*")
    if falling:
        for it, delta in falling[:FALLING_LIMIT]:
            lines.append(f"- {clean_name(it['name'])} â†’ *{it['rank']}ìœ„* (â–¼{delta})")
    else:
        lines.append("- í•´ë‹¹ ì—†ìŒ")

    # ë­í¬ ì¸&ì•„ì›ƒ ê°œìˆ˜ ë¬¸ì¥
    lines.append("")
    lines.append(f"ğŸ“ *ë§í¬ ì¸&ì•„ì›ƒ*\n{inout_count}ê°œì˜ ì œí’ˆì´ ì¸&ì•„ì›ƒ ë˜ì—ˆìŠµë‹ˆë‹¤.")

    return "\n".join(lines)

# --------------------- Slack ì „ì†¡ ---------------------
def send_slack(text: str):
    url = os.getenv("SLACK_WEBHOOK_URL", "").strip()
    if not url:
        log.warning("SLACK_WEBHOOK_URL ë¯¸ì„¤ì • â†’ ìŠ¬ë™ ì „ì†¡ ìƒëµ")
        return
    try:
        resp = requests.post(url, json={"text": text}, timeout=10)
        if resp.status_code >= 400:
            log.warning("Slack ì „ì†¡ ì‹¤íŒ¨: %s %s", resp.status_code, resp.text[:200])
        else:
            log.info("Slack ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        log.warning("Slack ì „ì†¡ ì¤‘ ì˜ˆì™¸: %s", e)

# --------------------- Drive ì—…ë¡œë“œ ---------------------
def drive_upload_csv(path: pathlib.Path) -> Optional[str]:
    folder_id = os.getenv("GDRIVE_FOLDER_ID", "").strip()
    if not folder_id or not path.exists():
        return None
    try:
        creds = Credentials(
            None,
            refresh_token=os.getenv("GOOGLE_REFRESH_TOKEN"),
            token_uri="https://oauth2.googleapis.com/token",
            client_id=os.getenv("GOOGLE_CLIENT_ID"),
            client_secret=os.getenv("GOOGLE_CLIENT_SECRET"),
            scopes=["https://www.googleapis.com/auth/drive.file"],
        )
        svc = build("drive", "v3", credentials=creds)
        media = MediaFileUpload(str(path), mimetype="text/csv", resumable=True)
        body = {"name": path.name, "parents": [folder_id]}
        f = svc.files().create(body=body, media_body=media, fields="id").execute()
        file_id = f.get("id")
        log.info("Google Drive ì—…ë¡œë“œ ì™„ë£Œ: %s", file_id)
        return file_id
    except Exception as e:
        log.warning("Google Drive ì—…ë¡œë“œ ì‹¤íŒ¨: %s", e)
        return None

# --------------------- ë©”ì¸ ---------------------
def fetch_products() -> List[Dict]:
    # 1) HTTP
    try:
        html = fetch_http()
    except Exception as e:
        log.warning("HTTP ì‹¤íŒ¨ â†’ Playwright í´ë°±: %s", e)
        html = fetch_playwright()

    items = parse_qoo10(html)
    if not items:
        raise RuntimeError("Qoo10 ìˆ˜ì§‘ ê²°ê³¼ 0ê±´. ì…€ë ‰í„°/ë Œë”ë§ ì ê²€ í•„ìš”")

    # ë²ˆì—­ í•„ë“œ(ì˜µì…˜)
    if SHOW_TRANSLATION:
        names = [clean_name(x["name"]) for x in items[:TOP_N]]
        kos = ja_to_ko_batch(names)
        for i, it in enumerate(items[:TOP_N]):
            it["name_ko"] = kos[i] if i < len(kos) else ""
    else:
        for it in items[:TOP_N]:
            it["name_ko"] = ""

    return items

def main():
    log.info("ìˆ˜ì§‘ ì‹œì‘: %s", QOO10_URL)
    items = fetch_products()
    log.info("ìˆ˜ì§‘ ì™„ë£Œ: %d", len(items))

    # ì €ì¥
    save_csv(CSV_PATH, items)
    drive_upload_csv(CSV_PATH)

    # ë¹„êµìš© ì „ì¼ CSV
    prev_local = read_prev_from_drive()
    prev = load_csv(prev_local) if prev_local else []

    rising, newcomers, falling, inout = analyze(prev, items)

    # ìŠ¬ë™ ë©”ì‹œì§€
    top_items = items[:TOP_N]
    msg = build_slack_message(DATE_STR, top_items, rising, newcomers, falling, inout)
    send_slack(msg)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        log.exception("ì‹¤í–‰ ì‹¤íŒ¨: %s", e)
        sys.exit(1)
